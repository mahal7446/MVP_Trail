{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Model 2 Training: Corn & Blackgram Disease Detection\n",
                "\n",
                "**Goal:** Train a robust disease classification model for Corn and Blackgram crops\n",
                "\n",
                "**Key Improvements:**\n",
                "- ‚úÖ Documented preprocessing (must match prediction code!)\n",
                "- ‚úÖ Support for negative samples (non-crop images)\n",
                "- ‚úÖ Data augmentation\n",
                "- ‚úÖ Validation split\n",
                "- ‚úÖ Early stopping\n",
                "- ‚úÖ Model checkpointing"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup & Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from pathlib import Path\n",
                "\n",
                "import tensorflow as tf\n",
                "from tensorflow import keras\n",
                "from tensorflow.keras import layers\n",
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
                "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
                "\n",
                "# Check TensorFlow version\n",
                "print(f'TensorFlow version: {tf.__version__}')\n",
                "print(f'GPU Available: {tf.config.list_physical_devices(\"GPU\")}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Configuration\n",
                "\n",
                "**IMPORTANT:** These settings must match your prediction code!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ==================== CRITICAL SETTINGS ====================\n",
                "# These MUST match the prediction code in model_manager.py!\n",
                "\n",
                "IMG_SIZE = 224  # Image dimensions (224x224)\n",
                "BATCH_SIZE = 32\n",
                "EPOCHS = 50\n",
                "\n",
                "# PREPROCESSING: Choose ONE and document it!\n",
                "# Option 1: Normalize to [0, 1]\n",
                "RESCALE = 1./255.0\n",
                "# Option 2: ResNet preprocessing (use preprocess_input)\n",
                "# from tensorflow.keras.applications.resnet50 import preprocess_input\n",
                "\n",
                "# ===========================================================\n",
                "\n",
                "# Dataset paths\n",
                "DATA_DIR = 'datasets/corn_blackgram'  # Update this path!\n",
                "\n",
                "# Class names (must match folder names in dataset)\n",
                "CLASS_NAMES = [\n",
                "    'Blackgram_Healthy',\n",
                "    'Blackgram_Anthracnose',\n",
                "    'Blackgram_Yellow_Mosaic',\n",
                "    'Blackgram_Leaf_Crinkle',\n",
                "    'Blackgram_Powdery_Mildew',\n",
                "    'Corn_Healthy',\n",
                "    'Corn_Common_Rust',\n",
                "    'Corn_Gray_Leaf_Spot',\n",
                "    'Corn_Blight',\n",
                "    # 'Not_A_Plant'  # Add this if you have negative samples!\n",
                "]\n",
                "\n",
                "NUM_CLASSES = len(CLASS_NAMES)\n",
                "print(f'Number of classes: {NUM_CLASSES}')\n",
                "print(f'Class names: {CLASS_NAMES}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Dataset Structure Check\n",
                "\n",
                "Expected folder structure:\n",
                "```\n",
                "datasets/corn_blackgram/\n",
                "‚îú‚îÄ‚îÄ train/\n",
                "‚îÇ   ‚îú‚îÄ‚îÄ Blackgram_Healthy/\n",
                "‚îÇ   ‚îú‚îÄ‚îÄ Blackgram_Anthracnose/\n",
                "‚îÇ   ‚îú‚îÄ‚îÄ Corn_Healthy/\n",
                "‚îÇ   ‚îî‚îÄ‚îÄ ...\n",
                "‚îî‚îÄ‚îÄ validation/  (optional, will split from train if not present)\n",
                "    ‚îú‚îÄ‚îÄ Blackgram_Healthy/\n",
                "    ‚îî‚îÄ‚îÄ ...\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check if dataset exists\n",
                "data_path = Path(DATA_DIR)\n",
                "if not data_path.exists():\n",
                "    print(f\"‚ùå Dataset not found at: {DATA_DIR}\")\n",
                "    print(\"Please create the dataset folder and organize images by class!\")\n",
                "else:\n",
                "    print(f\"‚úÖ Dataset found at: {DATA_DIR}\")\n",
                "    \n",
                "    # Check for train/validation split\n",
                "    train_path = data_path / 'train'\n",
                "    val_path = data_path / 'validation'\n",
                "    \n",
                "    if train_path.exists():\n",
                "        print(f\"‚úÖ Train folder found\")\n",
                "        # Count images per class\n",
                "        for class_name in CLASS_NAMES:\n",
                "            class_path = train_path / class_name\n",
                "            if class_path.exists():\n",
                "                num_images = len(list(class_path.glob('*.jpg'))) + len(list(class_path.glob('*.png')))\n",
                "                print(f\"   - {class_name}: {num_images} images\")\n",
                "    else:\n",
                "        print(\"‚ö†Ô∏è No 'train' folder - will use entire dataset\")\n",
                "    \n",
                "    if val_path.exists():\n",
                "        print(f\"‚úÖ Validation folder found\")\n",
                "    else:\n",
                "        print(\"‚ö†Ô∏è No 'validation' folder - will split from training data (80/20)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Data Generators with Augmentation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training data augmentation\n",
                "train_datagen = ImageDataGenerator(\n",
                "    rescale=RESCALE,  # CRITICAL: Must match prediction!\n",
                "    validation_split=0.2,  # 80% train, 20% validation\n",
                "    rotation_range=20,\n",
                "    width_shift_range=0.2,\n",
                "    height_shift_range=0.2,\n",
                "    shear_range=0.2,\n",
                "    zoom_range=0.2,\n",
                "    horizontal_flip=True,\n",
                "    fill_mode='nearest'\n",
                ")\n",
                "\n",
                "# Validation data (no augmentation, only rescaling)\n",
                "val_datagen = ImageDataGenerator(\n",
                "    rescale=RESCALE,  # CRITICAL: Must match prediction!\n",
                "    validation_split=0.2\n",
                ")\n",
                "\n",
                "# Create train generator\n",
                "train_generator = train_datagen.flow_from_directory(\n",
                "    DATA_DIR if not (Path(DATA_DIR) / 'train').exists() else str(Path(DATA_DIR) / 'train'),\n",
                "    target_size=(IMG_SIZE, IMG_SIZE),\n",
                "    batch_size=BATCH_SIZE,\n",
                "    class_mode='categorical',\n",
                "    subset='training',\n",
                "    shuffle=True,\n",
                "    seed=42\n",
                ")\n",
                "\n",
                "# Create validation generator\n",
                "val_generator = val_datagen.flow_from_directory(\n",
                "    DATA_DIR if not (Path(DATA_DIR) / 'train').exists() else str(Path(DATA_DIR) / 'train'),\n",
                "    target_size=(IMG_SIZE, IMG_SIZE),\n",
                "    batch_size=BATCH_SIZE,\n",
                "    class_mode='categorical',\n",
                "    subset='validation',\n",
                "    shuffle=False,\n",
                "    seed=42\n",
                ")\n",
                "\n",
                "print(f\"\\n‚úÖ Data generators created:\")\n",
                "print(f\"   Training samples: {train_generator.samples}\")\n",
                "print(f\"   Validation samples: {val_generator.samples}\")\n",
                "print(f\"   Class indices: {train_generator.class_indices}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Visualize Sample Images"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get a batch of images\n",
                "sample_images, sample_labels = next(train_generator)\n",
                "\n",
                "# Plot first 9 images\n",
                "plt.figure(figsize=(12, 12))\n",
                "for i in range(9):\n",
                "    plt.subplot(3, 3, i + 1)\n",
                "    # Denormalize for display\n",
                "    img = sample_images[i]\n",
                "    if RESCALE == 1./255.0:\n",
                "        img = img  # Already in [0, 1] for imshow\n",
                "    plt.imshow(img)\n",
                "    \n",
                "    # Get class name\n",
                "    class_idx = np.argmax(sample_labels[i])\n",
                "    class_name = list(train_generator.class_indices.keys())[class_idx]\n",
                "    plt.title(class_name)\n",
                "    plt.axis('off')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Build Model Architecture\n",
                "\n",
                "Using Transfer Learning with ResNet50 (pre-trained on ImageNet)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras.applications import ResNet50\n",
                "\n",
                "# Load pre-trained ResNet50 (without top layers)\n",
                "base_model = ResNet50(\n",
                "    weights='imagenet',\n",
                "    include_top=False,\n",
                "    input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
                ")\n",
                "\n",
                "# Freeze base model layers (optional: unfreeze later for fine-tuning)\n",
                "base_model.trainable = False\n",
                "\n",
                "# Build complete model\n",
                "model = keras.Sequential([\n",
                "    base_model,\n",
                "    layers.GlobalAveragePooling2D(),\n",
                "    layers.Dropout(0.5),\n",
                "    layers.Dense(512, activation='relu'),\n",
                "    layers.Dropout(0.3),\n",
                "    layers.Dense(NUM_CLASSES, activation='softmax')\n",
                "])\n",
                "\n",
                "# Compile model\n",
                "model.compile(\n",
                "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
                "    loss='categorical_crossentropy',\n",
                "    metrics=['accuracy', keras.metrics.TopKCategoricalAccuracy(k=3, name='top_3_accuracy')]\n",
                ")\n",
                "\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Setup Callbacks"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create checkpoints directory\n",
                "os.makedirs('checkpoints', exist_ok=True)\n",
                "\n",
                "callbacks = [\n",
                "    # Save best model\n",
                "    ModelCheckpoint(\n",
                "        'checkpoints/model2_best.h5',\n",
                "        monitor='val_accuracy',\n",
                "        save_best_only=True,\n",
                "        mode='max',\n",
                "        verbose=1\n",
                "    ),\n",
                "    \n",
                "    # Early stopping\n",
                "    EarlyStopping(\n",
                "        monitor='val_loss',\n",
                "        patience=10,\n",
                "        restore_best_weights=True,\n",
                "        verbose=1\n",
                "    ),\n",
                "    \n",
                "    # Reduce learning rate on plateau\n",
                "    ReduceLROnPlateau(\n",
                "        monitor='val_loss',\n",
                "        factor=0.5,\n",
                "        patience=5,\n",
                "        min_lr=1e-7,\n",
                "        verbose=1\n",
                "    )\n",
                "]\n",
                "\n",
                "print(\"‚úÖ Callbacks configured\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Train Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"üöÄ Starting training...\\n\")\n",
                "\n",
                "history = model.fit(\n",
                "    train_generator,\n",
                "    epochs=EPOCHS,\n",
                "    validation_data=val_generator,\n",
                "    callbacks=callbacks,\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "print(\"\\n‚úÖ Training complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Visualize Training History"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot training history\n",
                "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
                "\n",
                "# Accuracy\n",
                "axes[0].plot(history.history['accuracy'], label='Train Accuracy')\n",
                "axes[0].plot(history.history['val_accuracy'], label='Val Accuracy')\n",
                "axes[0].set_title('Model Accuracy')\n",
                "axes[0].set_xlabel('Epoch')\n",
                "axes[0].set_ylabel('Accuracy')\n",
                "axes[0].legend()\n",
                "axes[0].grid(True)\n",
                "\n",
                "# Loss\n",
                "axes[1].plot(history.history['loss'], label='Train Loss')\n",
                "axes[1].plot(history.history['val_loss'], label='Val Loss')\n",
                "axes[1].set_title('Model Loss')\n",
                "axes[1].set_xlabel('Epoch')\n",
                "axes[1].set_ylabel('Loss')\n",
                "axes[1].legend()\n",
                "axes[1].grid(True)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('training_history.png')\n",
                "plt.show()\n",
                "\n",
                "# Print final metrics\n",
                "print(f\"\\nFinal Metrics:\")\n",
                "print(f\"Train Accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
                "print(f\"Val Accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
                "print(f\"Train Loss: {history.history['loss'][-1]:.4f}\")\n",
                "print(f\"Val Loss: {history.history['val_loss'][-1]:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Save Final Model & Preprocessing Info"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save the final model\n",
                "model.save('Model2(Corn and Blackgram).h5')\n",
                "print(\"‚úÖ Model saved as 'Model2(Corn and Blackgram).h5'\")\n",
                "\n",
                "# CRITICAL: Save preprocessing info\n",
                "import json\n",
                "\n",
                "preprocessing_info = {\n",
                "    \"model_name\": \"Model2(Corn and Blackgram)\",\n",
                "    \"img_size\": IMG_SIZE,\n",
                "    \"rescale\": RESCALE,\n",
                "    \"preprocessing\": \"Normalize to [0, 1] by dividing by 255.0\",\n",
                "    \"classes\": list(train_generator.class_indices.keys()),\n",
                "    \"num_classes\": NUM_CLASSES,\n",
                "    \"training_accuracy\": float(history.history['accuracy'][-1]),\n",
                "    \"validation_accuracy\": float(history.history['val_accuracy'][-1])\n",
                "}\n",
                "\n",
                "with open('model2_info.json', 'w') as f:\n",
                "    json.dump(preprocessing_info, f, indent=2)\n",
                "\n",
                "print(\"‚úÖ Preprocessing info saved to 'model2_info.json'\")\n",
                "print(\"\\n‚ö†Ô∏è IMPORTANT: Use this EXACT preprocessing in prediction code!\")\n",
                "print(f\"   Rescale: {RESCALE}\")\n",
                "print(f\"   Image size: {IMG_SIZE}x{IMG_SIZE}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Test Prediction (Sample)\n",
                "\n",
                "Test the model on a sample image to verify it works"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras.preprocessing import image as keras_image\n",
                "\n",
                "# Load a test image (update path)\n",
                "test_image_path = 'path/to/test/image.jpg'  # CHANGE THIS!\n",
                "\n",
                "if os.path.exists(test_image_path):\n",
                "    # Load and preprocess\n",
                "    img = keras_image.load_img(test_image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
                "    img_array = keras_image.img_to_array(img)\n",
                "    img_array = img_array * RESCALE  # Apply same preprocessing!\n",
                "    img_array = np.expand_dims(img_array, axis=0)\n",
                "    \n",
                "    # Predict\n",
                "    predictions = model.predict(img_array)\n",
                "    \n",
                "    # Get top prediction\n",
                "    class_idx = np.argmax(predictions[0])\n",
                "    confidence = predictions[0][class_idx]\n",
                "    class_name = list(train_generator.class_indices.keys())[class_idx]\n",
                "    \n",
                "    # Display\n",
                "    plt.figure(figsize=(8, 6))\n",
                "    plt.imshow(img)\n",
                "    plt.title(f\"Prediction: {class_name}\\nConfidence: {confidence*100:.2f}%\")\n",
                "    plt.axis('off')\n",
                "    plt.show()\n",
                "    \n",
                "    # Show top 3 predictions\n",
                "    top_3_idx = np.argsort(predictions[0])[-3:][::-1]\n",
                "    print(\"\\nTop 3 Predictions:\")\n",
                "    for idx in top_3_idx:\n",
                "        class_name = list(train_generator.class_indices.keys())[idx]\n",
                "        conf = predictions[0][idx] * 100\n",
                "        print(f\"  {class_name}: {conf:.2f}%\")\n",
                "else:\n",
                "    print(f\"Test image not found: {test_image_path}\")\n",
                "    print(\"Update the path to test prediction!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 12. Next Steps\n",
                "\n",
                "1. ‚úÖ **Copy model to backend:**\n",
                "   ```bash\n",
                "   cp Model2(Corn\\ and\\ Blackgram).h5 ../backend/models/\n",
                "   ```\n",
                "\n",
                "2. ‚úÖ **Update prediction code** in `model_manager.py`:\n",
                "   - Set `RESCALE = 1./255.0` (or match your choice)\n",
                "   - Set `IMG_SIZE = 224`\n",
                "\n",
                "3. ‚úÖ **Update class labels** in `class_labels.json`:\n",
                "   ```json\n",
                "   \"corn_blackgram\": [\n",
                "     \"Blackgram_Healthy\",\n",
                "     \"Blackgram_Anthracnose\",\n",
                "     ...\n",
                "   ]\n",
                "   ```\n",
                "\n",
                "4. ‚úÖ **Test with real images** to verify predictions!\n",
                "\n",
                "---\n",
                "\n",
                "**Training Complete! üéâ**"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}